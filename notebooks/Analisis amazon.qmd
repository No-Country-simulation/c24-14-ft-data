---
title: Comportamiento de usuarios de Amazon
jupyter: python3
lang: es
execute:
  echo: false
  output: false
---

```{python}
!pip install -r ../requirements.txt
```

# Introducción

Amazon es una de las principales empresas de comercio en línea a nivel mundial. Para comprender mejor el comportamiento de los consumidores, se ha recopilado información a través de una encuesta, obteniendo datos sobre diversos aspectos de su interacción con la plataforma.

El conjunto de datos incluye características demográficas de los clientes, como edad y género, así como información sobre sus hábitos de compra, las categorías de productos que prefieren, la frecuencia con la que visitan la página y las razones por las que abandonan el carrito de compras, entre otros factores.

Mediante el análisis de esta información, es posible identificar patrones de comportamiento y desarrollar estrategias para optimizar la plataforma, mejorar la experiencia del usuario y aumentar la conversión de ventas.

# Objetivo

El objetivo principal de este análisis es identificar los factores que influyen en el abandono del carrito de compras en Amazon. Se busca determinar qué variables están relacionadas con este comportamiento y cuáles tienen un mayor impacto, con el fin de generar insights que ayuden a optimizar la plataforma y mejorar la experiencia del usuario.

# Preprocesameinto y limpieza de datos

```{python}
# Importacion de librerias


import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from scipy import stats as st
from scipy.stats import levene

# Importacion de dataset



from typing import Final
import os
import kagglehub


pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

kaggle_path = (
    kagglehub.dataset_download(
        "swathiunnikrishnan/amazon-consumer-behaviour-dataset"
    )
)

PATH: Final = os.path.join(kaggle_path, 'Amazon Customer Behavior Survey.csv')

df = pd.read_csv(PATH)
df['id'] = df.index + 1
```

```{python}
# Vista general

df.info()
```

Se ve que se tiene dos columnas con el mismo nombre `Personalized_Recommendation_Frequency`. Es así que decidimos cambiar el nombre de una para poder diferenciarlas entre si, incluso nos percatamos que una de ellas tenía un espacio de más

```{python}
# Editamos nombre de columna repetido

columns_with_indices = list(enumerate(df.columns))

# Print column names and their indices
print("Column Names and Indices:")
for index, col_name in columns_with_indices:
    print(f"Index: {index}, Column Name: '{col_name}'")


df=df.rename(columns={df.columns[17]:'Personalized_Recommendation_Frequency_2'})



# Editamos espacios de nombre de columnas


df.columns=df.columns.str.strip()
```

Aquí modificamos el nombre de unas de las columnas y eliminamos espacios innecesarios en los nombres

```{python}
#Previsualizamos el dataset

df.head()
```

```{python}
# Ver si hay datos nulos 


df.isna().sum()
```

```{python}
print(df['Product_Search_Method'].unique())
```

Se tienen dos datos nulos en la columna product_search_methos, sin embargo los dejaremos en nan

```{python}
# Checamos si hay duplicados


df.duplicated().sum()
```

```{python}
# Visualizamos cuantos valores unicos hay por categoria

print(df.nunique())
```

```{python}
# Vemos una descripcion general de los datos

df.describe()
```

Vemos que dentro de nuestros datos hay personas menores de edad, habiendo edades de hasta 3 años,para tener una cuenta en amazon se debe de tener por lo menos 13 años, es asi que procederemos a ver cuenta gente hay de esta edad

```{python}
# Vemos cuanto gente menor a 13 de edad hay


edades = df['age'].value_counts().sort_index()



menores = edades[edades.index < 13]

print(menores)

print(f'El total de menores de edad son {menores.sum()}')
```

```{python}
sns.boxplot(y=df['age'])
```

Como se puede observar en total hay 2  menores a 13 años de edad, procederemos a eliminar estas filas, esto no afectara estadisticamente nuestros datos ya que son solo 2 filas de 600 las que eliminaremos

```{python}
df = df[df['age'] >= 13]

df.describe()
```

```{python}
sns.boxplot(y=df['age'])
```

Como podemos ver, al eliminar a los menores de 13 años, ya no hay valores atípicos por debajo del primer cuartil en nuestro boxplot. Incluso si comparamos la media y la desviación estándar después de eliminar a los menores de edad con los valores originales, prácticamente se mantienen iguales: la media pasa de 30.79 a 30.868, y la desviación estándar de 10.19 a 10.117556, respectivamente.

```{python}
df.head()
```

# Análisis de datos

## Análisis variables categóricas

En esta sección analizaremos los datos de las variables categóricas para tener una estadística general lo que se recolectó

```{python}
# Obtenemos las fechas del analisis de comportamiento

df['Timestamp'] = pd.to_datetime(df['Timestamp'])
 
fecha_minima = df['Timestamp'].min()
fecha_maxima = df['Timestamp'].max()

print(f'La fecha mínima de compra es {fecha_minima}')
print(f'La fecha máxima de compra es {fecha_maxima}')
print(f'Rango de fechas: {fecha_maxima - fecha_minima}')



df['Timestamp'].hist(bins=12, figsize=(10,5))
```

La recolección de datos fue hecha aproximadamente en un rango de 11 días

```{python}
# Distribucion de datos por genero


value_counts = df['Gender'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Percentage Distribution of Gender')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

La mayoria de los datos recolectados de la población fueron mujeres con un 58%

```{python}
# Frecuencia de compra


value_counts = df['Purchase_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Percentage Distribution of Purchase frecuency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

- La mayoria de los usuarios dice que compra algunas veces al mes siendo un 33.7%
- 20.6% menos de una vez al mes
- 18.6% Una vez a la semana
- 17.8% una vez al mes
- 9.3% multiples veces al la semana

```{python}
# Obtenemos las categorias mas populares


purchases_by_category = df['Purchase_Categories'].value_counts()



print(purchases_by_category)


# Plot the bar chart
purchases_by_category.plot(title='Categorias', kind='barh', xlabel='Categorias', ylabel='Number of Purchases', figsize=[10,5])

# Show the plot
plt.show()
```

Como podemos ver tenemos alrededor de 29 categorías, las cuales reduciremos a las categorías únicas en el siguiente código

```{python}

#Categorias unicas
total_registros = len(df)
df_copy = df.copy()
df_copy['Purchase_Categories'] = df_copy['Purchase_Categories'].str.split(';')

df_copy = df_copy.explode('Purchase_Categories').reset_index(drop=True)

from matplotlib.patches import FancyBboxPatch


category_counts = df_copy['Purchase_Categories'].value_counts()

colors_top_five = ['#0072f0', '#0072f0', '#0072f0', '#0072f0', '#0072f0']

title_text: str = 'Preferencia de compras'


plt.figure(figsize=(6, 4))


ax = sns.barplot(
    x=category_counts.values,
    y=category_counts.index, orient='h',
    joinstyle='bevel'
)


new_patches = []
for patch, color, deck, total, in zip(
    ax.patches, colors_top_five,
    category_counts.values, category_counts.values
):

    bb = patch.get_bbox()
    p_bbox = FancyBboxPatch(
        (bb.xmin, bb.ymin), abs(bb.width), abs(bb.height),
        boxstyle='round,pad=-0.05,rounding_size=0.73',
        ec='none', fc=color, mutation_aspect=0.73
    )
    patch.remove()
    new_patches.append(p_bbox)

    ax.annotate(
        f'{(deck*100/total_registros):.0f}%', xy=(40, patch.get_y() + patch.get_height()/2),
        xytext=(-5,0), textcoords='offset points',
        arrowprops=dict(arrowstyle='-', color='none'),
        color='white', fontweight='bold', fontsize=12, ha='right', va='center',
        xycoords='data',
        bbox=dict(facecolor='none', edgecolor='none', pad=0),
        annotation_clip=False
    )

    ax.annotate(
        f'{total}',
        xy=(patch.get_width(), patch.get_y() + patch.get_height()/2),
        xytext=(-5,0), textcoords='offset points',
        arrowprops=dict(arrowstyle='-', color='none'),
        color='white', fontweight='bold', fontsize=12, ha='right', va='center',
        xycoords='data',
        bbox=dict(facecolor='none', edgecolor='none', pad=0),
        annotation_clip=False
    )

for patch in new_patches:
    ax.add_patch(patch)

ax.set_xlabel('')
ax.set_ylabel('')
ax.set_xticks([])
ax.yaxis.grid(False)
ax.xaxis.grid(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)

plt.title(
    title_text,
    fontsize=18, fontweight='bold', x=0.35
)

ax.text(
    0.98, 0.02, f'{total_registros}\nRegistros totales',
    ha='right', va='bottom', transform=ax.transAxes,
    fontsize=12, fontweight='bold'
)

plt.show()
```

Se puede apreciar que al final solo hay cinco categorias unicas, siendo que el 57% de los usarios prefieren ropa y moda, 53% belleza y cuidado personal, 36% hogar y cocina, 28% otros y comida el 18%

```{python}
#Combinaciones de categorias unicas por usuario

df_dummies = pd.get_dummies(df_copy['Purchase_Categories'])
df_combined = df_copy.join(df_dummies).groupby('id').max().reset_index()

df_combined.sample(10)
```

```{python}
"""
Armado del dataset para hacer la gráfica de venn
Calcular cuanto están en común y cuantos solo una categoría
"""

from matplotlib.ticker import FuncFormatter
from matplotlib.font_manager import fontManager, FontProperties
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib_venn import venn3


df_filtered = df_combined[['id'] + df_combined.columns[-5:].tolist()]
def comunidad(server: str, df: pd.DataFrame=df_filtered):
    '''
        Para filtrar sus usuarios únicos de cada comunidad
    '''
    return df.query(f'`{server}` == True')['id'].drop_duplicates()


comunidad_list_top_three = category_counts.index[:3].tolist()


comunity_top_one = comunidad(comunidad_list_top_three[0])
comunity_top_two = comunidad(comunidad_list_top_three[1])
comunity_top_three = comunidad(comunidad_list_top_three[2])

set_top_one = set(comunity_top_one)
set_top_two = set(comunity_top_two)
set_top_three = set(comunity_top_three)

# Calcular los tamaños de los conjuntos
size_100 = len(set_top_one - (set_top_two | set_top_three))
size_010 = len(set_top_two - (set_top_one | set_top_three))
size_001 = len(set_top_three - (set_top_one | set_top_two))
size_110 = len((set_top_one & set_top_two) - set_top_three)
size_101 = len((set_top_one & set_top_three) - set_top_two)
size_011 = len((set_top_two & set_top_three) - set_top_one)
size_111 = len(set_top_one & set_top_two & set_top_three)

# Calcular los porcentajes
total = sum(
    [size_100, size_010, size_001, size_110, size_101, size_011, size_111]
)

percent_100 = (size_100 / total_registros) * 100
percent_010 = (size_010 / total_registros) * 100
percent_001 = (size_001 / total_registros) * 100
percent_110 = (size_110 / total_registros) * 100
percent_101 = (size_101 / total_registros) * 100
percent_011 = (size_011 / total_registros) * 100
percent_111 = (size_111 / total_registros) * 100

ids_sum: int = int(df_filtered.id.drop_duplicates().count())

count_com = [total, int(ids_sum - total)]
labels_com = "Están en\nlas más \nsolicitadas", "No están\nen las más\nsolicitadas"
pastel_colors = ['#4995e8', '#BDFCFE']

title_text: str = "Relación de categorías de compra"

fig, ax = plt.subplots(figsize=(10, 8))

wedges, texts, autotexts = ax.pie(
    count_com, labels=labels_com, autopct="%1.1f%%",
    colors=pastel_colors,
    wedgeprops={'edgecolor': 'white', 'linewidth': 1, 'linestyle': 'solid'},
    pctdistance=0.75,
    textprops={'fontsize': 22}
)

centre_circle = plt.Circle((0, 0), 0.4, fc='white')
ax.add_artist(centre_circle)

ax.text(0, 0, f'{ids_sum}\ncompradores', ha='center', va='center', fontsize=21)

ax.set_title(
    title_text,
    fontsize=28,
    fontweight="bold"
)

plt.show()
```

Entre las categorías `Clothing and Fashion`, `Beauty and Personal Care`, `Home and Kitchen` hay una gran preferencia por los encuestados, prácticamente un 90% de ellos

```{python}
"""
Gráfico de Venn en sí
""""

fig, ax = plt.subplots(figsize=(10, 8))

venn = venn3(
    [set_top_one, set_top_two, set_top_three],
    set_labels=(
        comunidad_list_top_three[0],
        comunidad_list_top_three[1],
        comunidad_list_top_three[2]
    )
)

venn.get_label_by_id('100').set_text(
    f"{size_100}\n{percent_100:.2f}%")
venn.get_label_by_id('010').set_text(
    f"{size_010}\n{percent_010:.2f}%")
venn.get_label_by_id('001').set_text(
    f"{size_001}\n{percent_001:.2f}%")
venn.get_label_by_id('110').set_text(
    f"{size_110}\n{percent_110:.2f}%")
venn.get_label_by_id('101').set_text(
    f"{size_101}\n{percent_101:.2f}%")
venn.get_label_by_id('011').set_text(
    f"{size_011}\n{percent_011:.2f}%")
venn.get_label_by_id('111').set_text(
    f"{size_111}\n{percent_111:.2f}%")


colors = sns.color_palette('Set3', 7)
for patch, color in zip(venn.patches, colors):
    patch.set_facecolor(color)


for label in venn.set_labels:
    label.set_fontsize(20)

for label in venn.subset_labels:
    if label:
        label.set_fontsize(16)

ax.set_title(
    'Gráfico de Venn',
    fontsize=28,
    fontweight="bold"
)

plt.show()
```

A partir del mismo, podemos ver que el 16% de los encuestados son los que eligen las 3 categorías en concreto, solo detrás de los que eligen solo `Clothing and Fashion` o `Beauty and Personal Care`

```{python}
"""
A partir de las 3 categorías principales
Muestra gráfica de cuantos son que eligieron 1 de esos 3,
cuantos eligieron 2 y cuantos eligieron los 3
"""

fig, ax = plt.subplots(figsize=(10, 8))


unique_server = size_100 + size_010 + size_001
two_communities = size_110 + size_101 + size_011

count_duelists = [unique_server, two_communities, size_111]
labels = "Una\nsola", "En dos", "Están\nen\nlas 3"
pastel_colors = ['#92c6ff', '#ffb7ce', '#b7e3cc']


wedges, texts, autotexts = ax.pie(
    count_duelists, labels=labels, autopct="%1.1f%%",
    colors=pastel_colors,
    wedgeprops={'edgecolor': 'white', 'linewidth': 1, 'linestyle': 'solid'},
    pctdistance=0.75,
    textprops={'fontsize': 20}
)

centre_circle = plt.Circle((0, 0), 0.4, fc='white')
ax.add_artist(centre_circle)

ax.text(0, 0, f'{total}\ncompradores', ha='center', va='center', fontsize=21)

ax.set_title(
    'De las 3, en cuántas\ncategorías de compras están',
    fontsize=24,
    fontweight="bold"
)


plt.show()
```

Comparando solo las categorías más solicitadas vemos que 293 encuestados son los que eligen solamente uno de las tres.

```{python}
# Dsitribucions de frecuencia si los usarios han hecho alguna compra basado en los recomendaciones de amazon

value_counts = df['Personalized_Recommendation_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Personalized_Recommendation_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

El 20.3% dice que si ha hecho compras basado en las recomendaciones de amazon, 38% de los usuarios dicen que a veces y 41.7% dice que no 

```{python}
#Frecuencia de navegacion


value_counts = df['Browsing_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Browsing_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

La mayoría de los usuarios dice que navega algunas veces por semana, siendo un 41.4%, el 33.1% dice que navega algunas veces por mes, el 12.8% dice que navega múltiples veces en el día, y también el 12.8% dice que raramente.

```{python}
# Como buscas los productos?

value_counts = df['Product_Search_Method'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Product_Search_Method')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

El 37.2% de los usuarios dijo que su método de búsqueda era por categorías, el 35.7% dijo que era por palabras clave, el 21.2% dijo que era por filtros, y el 6% dijo otros.

```{python}
#Busqueda en primera pagina o multiples paginas


value_counts = df['Search_Result_Exploration'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Search_Result_Exploration')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

73.4% de los usuarios dijo que tiende a navegar en múltiples páginas, mientras que el 26.6% dijo que se enfoca en la primera página

```{python}
# Agregas al carrito mientras naveghas

value_counts = df['Add_to_Cart_Browsing'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Add_to_Cart_Browsing')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

41.2% de usuarios dijo que tal vez agregaba al carrito mientras navegaba,  35.9% dijo que sí y 22.9% dijo que no

```{python}
# Que tan seguido se completa la compra despues de agregar ala carrito


value_counts = df['Cart_Completion_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Completion_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

- 50.3% de los usarios dijeron que aq veces completaban el carrito
- 26.3 que siempre lo completaban
- 12% rara vez completaban el carrito
- 7.8% siempre completaban el carrito
- 3.5% nunca completaban el carrito

```{python}
# Frecuencia de distribucion categorias abandono de carrito
value_counts = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Abandonment_Factors')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Prácticamente aquí podemos ver que los factores de abandono de carrito que más sobresalen son 'Se encontró un mejor precio en otro lugar' con un 42.2%, 'Se cambió de opinión o ya no se necesita el producto' con un 40.2%, y después con 11.7% y 6.0% están 'Altos costos de envío' y 'otros', respectivamente

```{python}
# Frecuencia del uso de funcion save for later

value_counts = df['Saveforlater_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Saveforlater_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Respecto al uso de la funcion 'Guardar para mas tarde'

- 41.8% de los usuarios dijo que a veces la utilizaba
- 25.8% dijp que la utilizaba seguido
- 13.7% de los usuarios dijo que raramente la utilizaba
- 9.8% de los usuarios dijo que nunca la utilizaba
- 8..8% de los usuarios dijo que siempre la utilizaba

```{python}
# Resena hecha

value_counts = df['Review_Left'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Left')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Practicamente mitad y mitad dejan o no resena siendo un 48.7% que no y 51.3% que si

```{python}
# Confianza en las resenas al hacer compra



value_counts = df['Review_Reliability'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Reliability')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Aquí se le preguntó al usuario qué tanto confía en las reseñas de los productos, para lo cual:

- 33% dijo que confía moderadamente.

- 31.5% dijo que ocasionalmente confía en las reseñas.

- 24.8% dijo que confía fuertemente.

- 6.8% raramente confiaba en las reseñas.

- 3.8% nunca confiaba en las reseñas.

```{python}
# Las resenas de otros clientes son utiles?


value_counts = df['Review_Helpfulness'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Helpfulness')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

En esta grafica se ve que el 39.3% de los clientes considera util las resenas, 37.7% dijo que a veces las considera utiles y el 23% dijo que no las considera utiles

```{python}
# Recomendaciones utiles



value_counts = df['Recommendation_Helpfulness'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Recommendation_Helpfulness')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Los usarios que consideraron que las rcomendaciones a veces eran utiles fue de un 45.2%, los que dijeron que no eran utiles fue de un 28.7% y los que dijeron que si eran utiles fue de un 26.2%

```{python}
# Aspectos de servicio que mas se valoran


value_counts = df['Service_Appreciation'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Service_Appreciation')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Dentro de los aspectos de servicio que más destacaban los usuarios fueron:

- Recomendaciones de productos con un 30.8%.

- Precios competitivos con un 30.2%.

- Variedad de productos con un 24.8%.

- Interfaz amigable de la aplicación con un 13.3%.

```{python}
# Areas a mejorar


value_counts = df['Improvement_Areas'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Improvement_Areas')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

Dentro de las principales áreas a mejorar según los usuarios fueron:

- 35.8% dijo que la respuesta de servicio al cliente.

- 26.5% la calidad del producto.

- 22.2% reducción de los residuos de empaque.

- 13.2% rapidez y confianza de envío.

### Análisis prueba chi cuadrada para independencia variables vs factores de abandono de carrito

Para el analisis de las variables categoricas y su relacion con los factores de abandono de carrito se realizara una prueba chi cuadrada para independencia para ver si hay algun tipo de relacion

```{python}
from scipy.stats import chi2_contingency



# Realizamos una funcion para realizar la pureba chi cuadrada de cada variable vs factores de abandono de carrito
def analyze_cart_abandonment(df, cart_abandonment_col, exclude_col=None):
 
    # Seleccionamos solo las variables categoricas (object, category, or bool types)
    categorical_columns = df.select_dtypes(include=['object', 'category', 'bool']).columns
    
    # Removemos la columna de abandono de carrito
    categorical_columns = [col for col in categorical_columns if col != cart_abandonment_col and col != exclude_col]
    
    if not categorical_columns:
        print("No categorical columns found in the DataFrame.")
        return
    
    rejected_columns = []

    for col in categorical_columns:
        print(f"\nAnalisis '{col}' vs '{cart_abandonment_col}':")
        
        # Creacion de tabla de contingenca
        cross_tab = pd.crosstab(df[col], df[cart_abandonment_col])
        print("Cross-Tabulation Table:")
        print(cross_tab)
        
        # Visualize de tabla de contingencia
        plt.figure(figsize=(10, 4))
        sns.heatmap(cross_tab, annot=True, fmt='d', cmap='coolwarm')
        plt.title(f'Cart Abandonment Factors por {col}')
        plt.show()
        
        #  Chi-Square test
        chi2, p, dof, expected = chi2_contingency(cross_tab)
        print(f"Chi-Square Statistic: {chi2}")
        print(f"p-value: {p}")
        print(f"Degrees of Freedom: {dof}")
        print("Expected Frequencies Table:")
        print(expected)
        print()

        alpha = .05
        if p < alpha:
            print(f'Conclusion: Como p_value ({p:.4f}) es menor a alpha de {alpha}, rechazamos la H0(hipotesis nula)')
            print()

            print(f'Por lo tanto hay diferencias significativas entre los grupos, es decir que hay evidencia estadistica para decir que existe una asociacion entre {col} y  Cart_Abandonment_Factors')
            rejected_columns.append(col)
        else:
            print(f'Conclusion: Como p_value  ({p:.4f}) es mayor a alpha de {alpha}, no hay suficiente evidencia para rechazar  H0(hipotesis nula)')
            print()

            print(f'Por lo tanto no hay diferencias significativas entre los grupos, es decir que NO hay evidencia estadistica para decir que existe una asociacion entre {col} y  Cart_Abandonment_Factors')


        print("-" * 50)
    
    return rejected_columns


analyze_cart_abandonment(df, 'Cart_Abandonment_Factors', exclude_col='Purchase_Categories') 
```

```{python}
# Creacion de tabla de contingenca para test de categorias de compra unicas y factores de abandono de carrito
cross_tab = pd.crosstab(df_copy['Purchase_Categories'], df_copy['Cart_Abandonment_Factors'])
print("Cross-Tabulation Table:")
print(cross_tab)

# Visualize de tabla de contingencia
plt.figure(figsize=(10, 4))
sns.heatmap(cross_tab, annot=True, fmt='d', cmap='coolwarm')
plt.title(f'Cart Abandonment Factors por categorias de compra unicas')
plt.show()

#  Chi-Square test
chi2, p, dof, expected = chi2_contingency(cross_tab)
print(f"Chi-Square Statistic: {chi2}")
print(f"p-value: {p}")
print(f"Degrees of Freedom: {dof}")
print("Expected Frequencies Table:")
print(expected)
print()

alpha = .05
if p < alpha:
    print(f'Conclusion: Como p_value ({p:.4f}) es menor a alpha de {alpha}, rechazamos la H0(hipotesis nula)')
    print()

    print(f'Por lo tanto hay diferencias significativas entre los grupos, es decir que hay evidencia estadistica para decir que existe una asociacion entre Purchase categories y  Cart_Abandonment_Factors')
    rejected_columns.append(col)
else:
    print(f'Conclusion: Como p_value  ({p:.4f}) es mayor a alpha de {alpha}, no hay suficiente evidencia para rechazar  H0(hipotesis nula)')
    print()

    print(f'Por lo tanto no hay diferencias significativas entre los grupos, es decir que NO hay evidencia estadistica para decir que existe una asociacion entre Purchase categories y  Cart_Abandonment_Factors')


print("-" * 50)
```

### Conclusiones por categoria

`Browsing_Frequency`

- Se puede concluir que existe una relación entre la frecuencia de navegación y los factores de abandono de carrito, ya que los usuarios que se conectan algunas veces a la semana y encuentran mejores precios en otros sitios son quienes abandonan más el carrito.


`Product_Search_Method`
- Se puede concluir que existe una relación entre el método de búsqueda de producto y los factores de abandono de carrito, ya que los usuarios que buscan por categoría y cambian de opinión o ya no necesitan el artículo son quienes más abandonan el carrito.  Dime cuantas veces por se repite que la conclusion es una de estas cuatro , cambio de opinion y/o ya no necesia el articulo, encontrpo mejor precio en otro lugar, altos costos de envio, otros 


`Search_Result_Exploration`
Se puede concluir que existe una relación entre la exploración de resultados de búsqueda y los factores de abandono de carrito, ya que los usuarios que navegaron en múltiples páginas y encontraron un mejor precio en otro lugar son quienes más abandonan el carrito.

`Cart_Completion_Frequency`
- Se puede concluir que existe una relación entre la frecuencia con la que se completa el carrito y los factores de abandono de carrito, ya que los usuarios que seguido completan el carrito y que encuentran un precio en un mejor lugar son los que más abandonan.

`Saveforlater_Frequency`
- Se puede concluir que existe una relación entre el uso de la función "guardar para más tarde" y los factores de abandono de carrito, ya que los usuarios que a veces usan la función "guardar para más tarde" y que encuentran un precio en un mejor lugar son los que más abandonan.

`Review_Reliability`
- Se puede concluir que existe una relación entre la confianza en las reseñas de producto y los factores de abandono de carrito, ya que los usuarios que ocasionalmente confían en la reseña de producto y encuentran un precio en otro lugar son los que más abandonan.

`Review_Helpfulness`
- Se puede concluir que existe una relación entre la utilidad de la información de las reseñas de producto y los factores de abandono de carrito, ya que los usuarios que a veces encontraban utilidad en la información de las reseñas y cambiaban de opinión o ya no necesitaban el artículo son los que más abandonan.

`Recommendation_Helpfulness`
- Se puede concluir que existe una relación entre la utilidad de las recomendaciones y los factores de abandono de carrito, ya que los usuarios que hallaban las recomendaciones útiles y abandonaban por altos costos de envío son los que más abandonaban. Después de ahí, los que más abandonan son los que no habían encontrado las recomendaciones útiles y cambiaban de opinión o ya no necesitaban el artículo.

`Service_Appreciation`
- Se puede concluir que existe una relación entre el aspecto del servicio de Amazon que más apreciaban y los factores de abandono de carrito, ya que los usuarios que apreciaban el precio competitivo y encontraban un mejor precio en otro lugar son los que más abandonaban. Los segundos que más abandonan son los que apreciaban las recomendaciones de productos y abandonaban ya sea porque cambiaban de opinión y ya no necesitaban el artículo o porque encontraron un mejor precio en otro lugar.

`Improvement_Areas`
- Se puede concluir que existe una relación entre las áreas que se creen que deben mejorar y los factores de abandono de carrito, ya que los usuarios que creían que Amazon tenía que mejorar su servicio en respuesta de servicio al cliente abandonaban ya sea porque cambiaban de opinión y ya no necesitaban el artículo o porque encontraron un mejor precio en otro lugar.

### Conclusion general variables categoricas

Se puede observar en que pruebas se ve cual fue la categoria de abandono mas frecuente

Cambio de opinión y/o ya no necesitaba el artículo → 4 veces

- Product_Search_Method
- Review_Helpfulness
- Recommendation_Helpfulness
- Service_Appreciation

Encontró mejor precio en otro lugar → 6 veces

- Browsing_Frequency
- Search_Result_Exploration
- Cart_Completion_Frequency
- Saveforlater_Frequency
- Review_Reliability
- Service_Appreciation

Altos costos de envío → 1 vez

- Recommendation_Helpfulness




En conclusión podemos decir que lo que más impacta para el abandono del carrito es que los usarios encuentran mejor precio en otro lugar, seguido de que cambiaron de opinion o ya no necesitan el articulo

## Analisis variables numericas

En esta sección analizaremos las variables numéricas que se tienen en el dataset para tener una destadística descriptiva de la recolección de datos

```{python}
# Obtenemos histogramas de las estadisticas numericas generales
columnas_numericas =  df.columns.drop(['Timestamp','id'])

df[columnas_numericas].hist(figsize=(15, 10))
```

Se obtiene los histogramas de las variables numericas en donde se puede ver que salen practicament de esta forma porque en la preguntas las opciones van del 1 al 5(a excepcion de edad) por ende los histogramas no obtienen una distribucion normal del todo o algun tipo de trend

```{python}
columnas_numericas =  df.drop(columns=['Timestamp','id'])

columnas_numericas = columnas_numericas.select_dtypes(include=['float64', 'int64'])

print(columnas_numericas.columns)
```

```{python}



correlation = columnas_numericas.corr()
plt.figure(figsize=(10,10))
sns.heatmap(correlation,annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation matrix')
plt.show()
```

```{python}
correlation_shopping_rating = df['Shopping_Satisfaction'].corr(df['Rating_Accuracy'])

print(correlation_shopping_rating)
```

```{python}


sns.regplot(x='Shopping_Satisfaction', y='Rating_Accuracy', data=df, scatter_kws = {'color':'blue'}, line_kws={'color' : 'red'})

plt.title('Correlacion satisfaction de compra  y relevancia de las recomendaciones')
plt.show()

group = df.groupby(['Shopping_Satisfaction', 'Rating_Accuracy']).size().reset_index(name='count')
print(group)
```

A pesar de que hay una correlacion de ..51 entre la satisfaccion de compra y la precision de las recomendaciones dadas se puede ver que esta correlacion al graficarrla no hay un patron muy claro pues recoredemos que al ser las opciones del 1-5 en cada categoria hace que se vea asi

# Analisis objetivo: Factores abandono de carrito

En esta sección, analizaremos la categoría o columna objetivo de los factores de abandono de carrito frente a los valores numéricos, con el fin de determinar si existe alguna diferencia entre un factor de abandono y ciertas categorías numéricas.

```{python}
# Imprimimos los factores unicos de abandono 

print(df['Cart_Abandonment_Factors'].unique())
```

```{python}
# Grafica de distribucion de factores de abandono
factor_counts = df['Cart_Abandonment_Factors'].value_counts()

# Factores de abandono 
factor_counts = factor_counts.sort_values(ascending=False)

percentage_per_value = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100

print(percentage_per_value)


value_counts = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Abandonment_Factors')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      

# Pareto chart para ver cuales son los factores de abandono que mas contribuyen 
      
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()

# Valores acumulados
cumulative_percentage = np.cumsum(factor_counts) / np.sum(factor_counts) * 100


#  Pareto chart
fig, ax1 = plt.subplots(figsize=(15,6))

# Barra frecuencias
ax1.bar(factor_counts.index, factor_counts, color='b')
ax1.set_xlabel(None)
ax1.set_ylabel('Frequency', color='b')
ax1.tick_params(axis='y', labelcolor='b')

# Line para el acumulado
ax2 = ax1.twinx()
ax2.plot(factor_counts.index, cumulative_percentage, color='r', marker='o')
ax2.set_ylabel('Cumulative Percentage', color='r')
ax2.tick_params(axis='y', labelcolor='r')

plt.xticks(rotation=45, ha='right')

plt.title('Pareto Chart of Cart Abandonment Factors')
plt.show()
```

En el primer gráfico de barras los factores de abandono de carrito podemos ver que los que mas sobresalen son que se encontró un mejor precio con un 42% y que mejor se cambia de opinión o ya no necesita mas el articulo con un 40% mientras que los otras dos categorías como la de alto costo de envío y otros representan el 11% y 5% respectivamente.

Después de eso se hace un pareto para saber cuales son los principales factores que se tendrían que analizar, que en este caso serian `Se encontró un mejor precio en otro lugar` y `Se cambió de opinión o no necesita más el artículo` pues son las que más efectos tienen al abandono

### T-test para las medias factores principales de abandono('Se encontro un mejor precio en otro lugar vs se cambio de opinion o ya no necesita el articulo') y variables numericas

Se hace un boxplot junto con un t-test de las medias de esas dos categorias de la variable factores de abandono de carrito vs las variables numericas para ver si hay diferencias siginificativas entre 'Se encuentra precio en un mejor lugar' y 'Cambio de opinion o ya no necesita el articulo'

```{python}
# Hacemo un box plot de los factores de abandono vs edad

categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['age'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'age', data=filtered_df)
plt.show()
print()
# Realizamos el levene test para confrimar que nestras varianzas sean iguales antes de hacer el ttest de medias

group1 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[0]]['age']
group2 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[1]]['age']

statistic, p_value = levene(group1, group2)
print("Levene's test statistic:", statistic)
print('p-value', p_value)


alpha = 0.05

if p_value < alpha:
    print('Se rechaza la hipotesis nula, varianzas son significativamente diferentes')
else:
    print('No se puede rechazar la hipotesis nula, varianzas no son significativamente diferenrtes')

print()


alpha = 0.05

results = st.ttest_ind(group1, group2, equal_var=(p_value>=alpha))

print('Valor p:', results.pvalue)

if results.pvalue < alpha:
    print('Rechazamos la hipotesis nula, es decir que hay diferencias significativas entre los dos grupos')
else:
    print('NO hay suficiente evidencia para rechazar la hipotesis nula, es decir que NO hay diferencias significativas entre los dos grupos')

```

Para la variable edad, no existe una diferencia significativa entre los grupos "Se encontró un mejor precio en otro lugar" y "Se cambió de opinión o ya no se necesita el producto", pues no hay evidencia estadística de que la edad sea un factor para abandonar el carrito por alguna de estas dos categorías.

```{python}
#Factores de abandono vs importancia de resenas de cliente


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['Customer_Reviews_Importance'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Customer_Reviews_Importance', data=filtered_df)
plt.show()
print()
# Realizamos el levene test para confrimar que nestras varianzas sean iguales antes de hacer el ttest de medias

group1 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[0]]['Customer_Reviews_Importance']
group2 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[1]]['Customer_Reviews_Importance']

statistic, p_value = levene(group1, group2)
print("Levene's test statistic:", statistic)
print('p-value', p_value)


alpha = 0.05

if p_value < alpha:
    print('Se rechaza la hipotesis nula, varianzas son significativamente diferentes')
    equal_var = False
else:
    print('No se puede rechazar la hipotesis nula, varianzas no son significativamente diferenrtes')
    equal_var = True

print()


alpha = 0.05

results = st.ttest_ind(group1, group2, equal_var=equal_var)

print('Valor p:', results.pvalue)

if results.pvalue < alpha:
    print('Rechazamos la hipotesis nula, es decir que hay diferencias significativas entre los dos grupos')
else:
    print('NO hay suficiente evidencia para rechazar la hipotesis nula, es decir que NO hay diferencias significativas entre los dos grupos')



```

Para la variable importancia de las resenas del cliente, no existe una diferencia significativa entre los grupos "Se encontró un mejor precio en otro lugar" y "Se cambió de opinión o ya no se necesita el producto", pues no hay evidencia estadística de que la importancia de las resenas del cliente sea un factor para abandonar el carrito por alguna de estas dos categorías.

```{python}
#Factores de abandono vs Que tan seguido se recibe recomendaciones personalizadas


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['Personalized_Recommendation_Frequency_2'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Personalized_Recommendation_Frequency_2', data=filtered_df)
plt.show()
print()
# Realizamos el levene test para confrimar que nestras varianzas sean iguales antes de hacer el ttest de medias

group1 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[0]]['Personalized_Recommendation_Frequency_2']
group2 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[1]]['Personalized_Recommendation_Frequency_2']

statistic, p_value = levene(group1, group2)
print("Levene's test statistic:", statistic)
print('p-value', p_value)


alpha = 0.05

if p_value < alpha:
    print('Se rechaza la hipotesis nula, varianzas son significativamente diferentes')
else:
    print('No se puede rechazar la hipotesis nula, varianzas no son significativamente diferenrtes')

print()


alpha = 0.05

results = st.ttest_ind(group1, group2, equal_var=(p_value>=alpha))

print('Valor p:', results.pvalue)

if results.pvalue < alpha:
    print('Rechazamos la hipotesis nula, es decir que hay diferencias significativas entre los dos grupos')
else:
    print('NO hay suficiente evidencia para rechazar la hipotesis nula, es decir que NO hay diferencias significativas entre los dos grupos')

```

```{python}
#Factores de abandono vs Que tan seguido se recibe recomendaciones personalizadas


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  
    descripcion = filtered_df['Rating_Accuracy'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Rating_Accuracy', data=filtered_df)
plt.show()
print()
# Realizamos el levene test para confrimar que nestras varianzas sean iguales antes de hacer el ttest de medias

group1 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[0]]['Rating_Accuracy']
group2 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[1]]['Rating_Accuracy']

statistic, p_value = levene(group1, group2)
print("Levene's test statistic:", statistic)
print('p-value', p_value)


alpha = 0.05

if p_value < alpha:
    print('Se rechaza la hipotesis nula, varianzas son significativamente diferentes')
else:
    print('No se puede rechazar la hipotesis nula, varianzas no son significativamente diferenrtes')

print()


alpha = 0.05

results = st.ttest_ind(group1, group2, equal_var=(p_value>=alpha))

print('Valor p:', results.pvalue)

if results.pvalue < alpha:
    print('Rechazamos la hipotesis nula, es decir que hay diferencias significativas entre los dos grupos')
else:
    print('NO hay suficiente evidencia para rechazar la hipotesis nula, es decir que NO hay diferencias significativas entre los dos grupos')

```

Para la variable relevancia y precision de las recomendaciones recibidas, no existe una diferencia significativa entre los grupos "Se encontró un mejor precio en otro lugar" y "Se cambió de opinión o ya no se necesita el producto", pues no hay evidencia estadística de que la relevancia y precision de las recomendaciones recibidas sea un factor para abandonar el carrito por alguna de estas dos categorías.

```{python}
#Factores de abandono vs Satisfaction de la compra


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  
    descripcion = filtered_df['Shopping_Satisfaction'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Shopping_Satisfaction', data=filtered_df)
plt.show()
print()
# Realizamos el levene test para confrimar que nestras varianzas sean iguales antes de hacer el ttest de medias

group1 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[0]]['Shopping_Satisfaction']
group2 =  df[df['Cart_Abandonment_Factors'] == categoria_abandono[1]]['Shopping_Satisfaction']

statistic, p_value = levene(group1, group2)
print("Levene's test statistic:", statistic)
print('p-value', p_value)


alpha = 0.05

if p_value < alpha:
    print('Se rechaza la hipotesis nula, varianzas son significativamente diferentes')
else:
    print('No se puede rechazar la hipotesis nula, varianzas no son significativamente diferenrtes')

print()


alpha = 0.05

results = st.ttest_ind(group1, group2, equal_var=(p_value>=alpha))

print('Valor p:', results.pvalue)

if results.pvalue < alpha:
    print('Rechazamos la hipotesis nula, es decir que hay diferencias significativas entre los dos grupos')
else:
    print('NO hay suficiente evidencia para rechazar la hipotesis nula, es decir que NO hay diferencias significativas entre los dos grupos')

```

Para la variable Satisfacion de comptra, no existe una diferencia significativa entre los grupos "Se encontró un mejor precio en otro lugar" y "Se cambió de opinión o ya no se necesita el producto", pues no hay evidencia estadística de que variable Satisfacion de comptra sea un factor para abandonar el carrito por alguna de estas dos categorías.

# Conclusiones

En conclusión, los factores que más destacan son que el cliente encuentra un mejor precio en otro lugar o que ya no necesita el artículo o cambia de opinión. Este abandono es dado primordialmente por las recomendaciones que se le dan al usuario y por la frecuencia de uso de las herramientas relacionadas, como lo son la función "guardar para más tarde", la frecuencia de completado del carrito y la forma de búsqueda (aquí la gente tiende a usar muchas páginas en lugar de una para la busqueda). Es así que las propuestas que se tienen son:

- Mejorar el algoritmo de recomendaciones de acuerdo a las actividades del usuario para que sean más personalizadas.

- Mejorar la interfaz para que sea más amigable en las funciones de completado de carrito, "guardar para más tarde", y agregar recordatorios de lo agregado o de lo abandonado.

- Hacer ofertas entre lo que busque el usuario y las recomendaciones que aparezcan en la página (algún tipo de paquete o combo), como agregar un producto complementario en el carrito.

- Ofrecer descuentos o cupones para usuarios frecuentes.

- Crear un sistema de recompensa por compras recurrentes, como lo puede ser puntos canjeables.

- Herramienta que permita comparar precios de productos similares directamente en Amazon.

