---
title: Introduccion
jupyter: python3
---

```{python}
!pip install -r ../requirements.txt
```

Amazon es una de las principales empresas de comercio en línea a nivel mundial. Para comprender mejor el comportamiento de los consumidores, se ha recopilado información a través de una encuesta, obteniendo datos sobre diversos aspectos de su interacción con la plataforma.

El conjunto de datos incluye características demográficas de los clientes, como edad y género, así como información sobre sus hábitos de compra, las categorías de productos que prefieren, la frecuencia con la que visitan la página y las razones por las que abandonan el carrito de compras, entre otros factores.

Mediante el análisis de esta información, es posible identificar patrones de comportamiento y desarrollar estrategias para optimizar la plataforma, mejorar la experiencia del usuario y aumentar la conversión de ventas.

# Objetivo

El objetivo principal de este análisis es identificar los factores que influyen en el abandono del carrito de compras en Amazon. Se busca determinar qué variables están relacionadas con este comportamiento y cuáles tienen un mayor impacto, con el fin de generar insights que ayuden a optimizar la plataforma y mejorar la experiencia del usuario.

# Preprocesameinto y limpieza de datos

```{python}
# Importacion de librerias


import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
```

```{python}
# Importacion de dataset


#df = pd.read_csv("C:/Users/janto/OneDrive/Documentos/No country/Amazon Customer Behavior Survey.csv")
from typing import Final
import os
import kagglehub


pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

kaggle_path = (
    kagglehub.dataset_download(
        "swathiunnikrishnan/amazon-consumer-behaviour-dataset"
    )
)

PATH: Final = os.path.join(kaggle_path, 'Amazon Customer Behavior Survey.csv')

df = pd.read_csv(PATH)
df['id'] = df.index + 1
```

```{python}
# Vista general

df.info()
```

Se ve que se tiene dos columnas con el mismo nombre 'Personalized_Recommendation_Frequency' Es asi que decidimos cambiar el nombre de una para poder diferenciarlas entre si, incluso nos percatamos que una de ellas tenia un espacio demas'

```{python}
# Editamos nombre de columna repetido

columns_with_indices = list(enumerate(df.columns))

# Print column names and their indices
print("Column Names and Indices:")
for index, col_name in columns_with_indices:
    print(f"Index: {index}, Column Name: '{col_name}'")


df=df.rename(columns={df.columns[17]:'Personalized_Recommendation_Frequency_2'})



# Editamos espacios de nombre de columnas


df.columns=df.columns.str.strip()
```

Aqui modificamos el nombre de unas de las columnas y eliminamos espacios innecesarios en los nombres

```{python}
#Previsualizamos el dataset

df.head()
```

```{python}
# Ver si hay datos nulos 


df.isna().sum()
```

```{python}
print(df['Product_Search_Method'].unique())
```

```{python}
# Checamos si hay duplicados


df.duplicated().sum()
```

```{python}
# Visualizamos cuantos valores unicos hay por categoria

print(df.nunique())
```

```{python}
# Vemos una descripcion general de los datos

df.describe()
```

Vemos que dentro de nustros datos hay personas menores de edad, habiendo edades de hasta 3 anos,para tener una cuenta en amazon se debe de tener por lo menos 13 anos, es asi que procederemos a ver cuenta gente hay de esta edad

```{python}
# Vemos cuanto gente menor de edad hay


edades = df['age'].value_counts().sort_index()



menores = edades[edades.index < 13]

print(menores)

print(f'El total de menores de edad son {menores.sum()}')
```


```{python}
sns.boxplot(y=df['age'])
```

Como se puede observar en total hay 2  menores a 13 anos de edad, prodederemos a eliminar estas filas, esto no afectara estadisticamente nuestros datos ya que son solo 2 filas de 600 las que eliminaremos

```{python}
df = df[df['age'] >= 13]

df.describe()
```

```{python}
sns.boxplot(y=df['age'])
```

Como podemos ver, al eliminar a los menores a 13 de edad, ya no hay valores atípicos por debajo del primer cuartil en nuestro boxplot. Incluso si comparamos la media y la desviación estándar después de eliminar a los menores de edad con los valores originales, prácticamente se mantienen iguales: la media pasa de 30.79 a 30.868, y la desviación estándar de 10.19 a 10.117556, respectivamente.

```{python}
df.head()
```

# Analisis de datos

## Analisis variables categoricas

En esta secciion analizaremos los datos de las variables categoricas para tener una estadistica general lo que se recolectó

```{python}
# Obtenemos las fechas del analisis de comportamiento

df['Timestamp'] = pd.to_datetime(df['Timestamp'])
 
fecha_minima = df['Timestamp'].min()
fecha_maxima = df['Timestamp'].max()

print(f'La fecha mínima de compra es {fecha_minima}')
print(f'La fecha máxima de compra es {fecha_maxima}')
print(f'Rango de fechas: {fecha_maxima - fecha_minima}')



df['Timestamp'].hist(bins=12, figsize=(10,5))
```

La recolección de datos fue hecha aproximadamente en un rango de 11 dias

```{python}
# Dastribucion de datos por genero


value_counts = df['Gender'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Percentage Distribution of Gender')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

La mayoria de los datos recolectados de la poblacion fueron mujeres con un 58%

```{python}
# Frecuencia de compra


value_counts = df['Purchase_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Percentage Distribution of Purchase frecuency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

-La mayoria de los usuarios dice que compra algunas veces al mes siendo un 33.7%, 
-20.6% menos de una vez al mes
-18.6% Una vez a la semana
-17.8% una vez al mes
-9.3% multiples veces al la semana

```{python}
# Obtenemos las categorias mas populares


purchases_by_category = df['Purchase_Categories'].value_counts()



print(purchases_by_category)


# Plot the bar chart
purchases_by_category.plot(title='Categorias', kind='barh', xlabel='Categorias', ylabel='Number of Purchases', figsize=[10,5])

# Show the plot
plt.show()
```

Como podemos ver tenemos alrededor de 29 categorias, las cuales reduciremos a las categorias unicas en el siguiente codigo

```{python}
total_registros = len(df)
df_copy = df.copy()
df_copy['Purchase_Categories'] = df_copy['Purchase_Categories'].str.split(';')

df_copy = df_copy.explode('Purchase_Categories').reset_index(drop=True)

from matplotlib.patches import FancyBboxPatch


category_counts = df_copy['Purchase_Categories'].value_counts()

colors_top_five = ['#0072f0', '#0072f0', '#0072f0', '#0072f0', '#0072f0']

title_text: str = 'Preferencia de compras'


plt.figure(figsize=(6, 4))


ax = sns.barplot(
    x=category_counts.values,
    y=category_counts.index, orient='h',
    joinstyle='bevel'
)


new_patches = []
for patch, color, deck, total, in zip(
    ax.patches, colors_top_five,
    category_counts.values, category_counts.values
):

    bb = patch.get_bbox()
    p_bbox = FancyBboxPatch(
        (bb.xmin, bb.ymin), abs(bb.width), abs(bb.height),
        boxstyle='round,pad=-0.05,rounding_size=0.73',
        ec='none', fc=color, mutation_aspect=0.73
    )
    patch.remove()
    new_patches.append(p_bbox)

    ax.annotate(
        f'{(deck*100/total_registros):.0f}%', xy=(40, patch.get_y() + patch.get_height()/2),
        xytext=(-5,0), textcoords='offset points',
        arrowprops=dict(arrowstyle='-', color='none'),
        color='white', fontweight='bold', fontsize=12, ha='right', va='center',
        xycoords='data',
        bbox=dict(facecolor='none', edgecolor='none', pad=0),
        annotation_clip=False
    )

    ax.annotate(
        f'{total}',
        xy=(patch.get_width(), patch.get_y() + patch.get_height()/2),
        xytext=(-5,0), textcoords='offset points',
        arrowprops=dict(arrowstyle='-', color='none'),
        color='white', fontweight='bold', fontsize=12, ha='right', va='center',
        xycoords='data',
        bbox=dict(facecolor='none', edgecolor='none', pad=0),
        annotation_clip=False
    )

for patch in new_patches:
    ax.add_patch(patch)

ax.set_xlabel('')
ax.set_ylabel('')
ax.set_xticks([])
ax.yaxis.grid(False)
ax.xaxis.grid(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)

plt.title(
    title_text,
    fontsize=18, fontweight='bold', x=0.35
)

ax.text(
    0.98, 0.02, f'{total_registros}\nRegistros totales',
    ha='right', va='bottom', transform=ax.transAxes,
    fontsize=12, fontweight='bold'
)

plt.show()
```

Se puede apreciar que al final solo hay cinco categorias unicas, siendo que el 57% de los usarios prefieren ropa y moda, 53% belleza y cuidado personal, 36% hogar y cocina, 28% otros y comida el 18%

```{python}
# df['Purchase_Categories'] = df['Purchase_Categories'].str.split(';')
# df = df.explode('Purchase_Categories').reset_index(drop=True)

df_dummies = pd.get_dummies(df_copy['Purchase_Categories'])
#df_combined = df.join(df_dummies).groupby('Timestamp').max().reset_index()
df_combined = df_copy.join(df_dummies).groupby('id').max().reset_index()
#df_combined = df.join(df_dummies).groupby('Timestamp').max().reset_index()

df_combined.sample(10)
```

```{python}
from matplotlib.ticker import FuncFormatter
from matplotlib.font_manager import fontManager, FontProperties
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib_venn import venn3


df_filtered = df_combined[['id'] + df_combined.columns[-5:].tolist()]
def comunidad(server: str, df: pd.DataFrame=df_filtered):
    '''
        Para filtrar sus usuarios únicos de cada comunidad
    '''
    return df.query(f'`{server}` == True')['id'].drop_duplicates()
```

```{python}
comunidad_list_top_three = category_counts.index[:3].tolist()


comunity_top_one = comunidad(comunidad_list_top_three[0])
comunity_top_two = comunidad(comunidad_list_top_three[1])
comunity_top_three = comunidad(comunidad_list_top_three[2])

set_top_one = set(comunity_top_one)
set_top_two = set(comunity_top_two)
set_top_three = set(comunity_top_three)

# Calcular los tamaños de los conjuntos
size_100 = len(set_top_one - (set_top_two | set_top_three))
size_010 = len(set_top_two - (set_top_one | set_top_three))
size_001 = len(set_top_three - (set_top_one | set_top_two))
size_110 = len((set_top_one & set_top_two) - set_top_three)
size_101 = len((set_top_one & set_top_three) - set_top_two)
size_011 = len((set_top_two & set_top_three) - set_top_one)
size_111 = len(set_top_one & set_top_two & set_top_three)

# Calcular los porcentajes
total = sum(
    [size_100, size_010, size_001, size_110, size_101, size_011, size_111]
)

percent_100 = (size_100 / total_registros) * 100
percent_010 = (size_010 / total_registros) * 100
percent_001 = (size_001 / total_registros) * 100
percent_110 = (size_110 / total_registros) * 100
percent_101 = (size_101 / total_registros) * 100
percent_011 = (size_011 / total_registros) * 100
percent_111 = (size_111 / total_registros) * 100

ids_sum: int = int(df_filtered.id.drop_duplicates().count())

count_com = [total, int(ids_sum - total)]
labels_com = "Están en\nlas más \nsolicitadas", "No están\nen las más\nsolicitadas"
pastel_colors = ['#4995e8', '#BDFCFE']

title_text: str = "Relación de categorías de compra"

fig, ax = plt.subplots(figsize=(10, 8))

wedges, texts, autotexts = ax.pie(
    count_com, labels=labels_com, autopct="%1.1f%%",
    colors=pastel_colors,
    wedgeprops={'edgecolor': 'white', 'linewidth': 1, 'linestyle': 'solid'},
    pctdistance=0.75,
    textprops={'fontsize': 22}
)

centre_circle = plt.Circle((0, 0), 0.4, fc='white')
ax.add_artist(centre_circle)

ax.text(0, 0, f'{ids_sum}\ncompradores', ha='center', va='center', fontsize=21)

ax.set_title(
    title_text,
    fontsize=28,
    fontweight="bold"
)

plt.show()
```

Adjuntar comentario - Lucel

```{python}
fig, ax = plt.subplots(figsize=(10, 8))

venn = venn3(
    [set_top_one, set_top_two, set_top_three],
    set_labels=(
        comunidad_list_top_three[0],
        comunidad_list_top_three[1],
        comunidad_list_top_three[2]
    )
)

venn.get_label_by_id('100').set_text(
    f"{size_100}\n{percent_100:.2f}%")
venn.get_label_by_id('010').set_text(
    f"{size_010}\n{percent_010:.2f}%")
venn.get_label_by_id('001').set_text(
    f"{size_001}\n{percent_001:.2f}%")
venn.get_label_by_id('110').set_text(
    f"{size_110}\n{percent_110:.2f}%")
venn.get_label_by_id('101').set_text(
    f"{size_101}\n{percent_101:.2f}%")
venn.get_label_by_id('011').set_text(
    f"{size_011}\n{percent_011:.2f}%")
venn.get_label_by_id('111').set_text(
    f"{size_111}\n{percent_111:.2f}%")


colors = sns.color_palette('Set3', 7)
for patch, color in zip(venn.patches, colors):
    patch.set_facecolor(color)


for label in venn.set_labels:
    label.set_fontsize(20)

for label in venn.subset_labels:
    if label:
        label.set_fontsize(16)

ax.set_title(
    'Gráfico de Venn',
    fontsize=28,
    fontweight="bold"
)

plt.show()
```

Adjuntar comentario - Lucel

```{python}
fig, ax = plt.subplots(figsize=(10, 8))


unique_server = size_100 + size_010 + size_001
two_communities = size_110 + size_101 + size_011

count_duelists = [unique_server, two_communities, size_111]
labels = "Una\nsola", "En dos", "Están\nen\nlas 3"
pastel_colors = ['#92c6ff', '#ffb7ce', '#b7e3cc']


wedges, texts, autotexts = ax.pie(
    count_duelists, labels=labels, autopct="%1.1f%%",
    colors=pastel_colors,
    wedgeprops={'edgecolor': 'white', 'linewidth': 1, 'linestyle': 'solid'},
    pctdistance=0.75,
    textprops={'fontsize': 20}
)

centre_circle = plt.Circle((0, 0), 0.4, fc='white')
ax.add_artist(centre_circle)

ax.text(0, 0, f'{total}\ncompradores', ha='center', va='center', fontsize=21)

ax.set_title(
    'De las 3, en cuántas\ncategorías de compras están',
    fontsize=24,
    fontweight="bold"
)


plt.show()
```

Adjuntar comentario - Lucel

```{python}
# Dsitribucions de frecuencia si los usarios han hecho alguna compra basado en los recomendaciones de amazon

value_counts = df['Personalized_Recommendation_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Personalized_Recommendation_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

El 20.3% dice que si ha hecho compras basado en las recomendaciones de amazon, 38% de los usuarios dicen que a veces y 41.7% dice que no 

```{python}
#Frecuencia de navegacion


value_counts = df['Browsing_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Browsing_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

La mayoria de lo usarios dice que navega algunas veces por semana siendo un 41.4%, 33.1% dice que navega agunas veces por mes, y 12.8% dice que multiples veces en el dia y yambien 12.8% dice que raramente

```{python}
# Como buscas los productos?

value_counts = df['Product_Search_Method'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Product_Search_Method')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

37.2% de los usuarios dijo  que su metodo de busqueda era por categorias, 35.7% dijo que era por palabras clave, 21.2% dijo que eran por filtro y 6% otros

```{python}
#Busqueda en primera pagina o multiples paginas


value_counts = df['Search_Result_Exploration'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Search_Result_Exploration')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

73.4% de los usarios ddijo que tiende a navegar en multiples paginas, mientrads que el 26.6% dijo que se enfoca en la primera pagina

```{python}
# Agregas al carrito mientras naveghas

value_counts = df['Add_to_Cart_Browsing'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Add_to_Cart_Browsing')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

41.2% de usuarios dijo que tal vez agregaba al carrito mientras navegaba,  35.9% dijo que si y 22.9% dijo que no

```{python}
# Que tan seguido se completa la compra despeus de agregar ala carrito


value_counts = df['Cart_Completion_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Completion_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Example: Frequency distribution of Cart_Abandonment_Factors
value_counts = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Abandonment_Factors')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Frecuencia del uso de funcion save for later

value_counts = df['Saveforlater_Frequency'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Saveforlater_Frequency')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Resena hecha

value_counts = df['Review_Left'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Left')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Confianza en las resenas al hacer compra



value_counts = df['Review_Reliability'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Reliability')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Las resenas de otors clientes son utiles?


value_counts = df['Review_Helpfulness'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Review_Helpfulness')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Recomendaciones utiles



value_counts = df['Recommendation_Helpfulness'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Recommendation_Helpfulness')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Aspectos de servicio que mas se valoran


value_counts = df['Service_Appreciation'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Service_Appreciation')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

```{python}
# Areas a mejorar


value_counts = df['Improvement_Areas'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Improvement_Areas')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()
```

### Analisis prueba chi cuadrada para independencia variables vs factores de abandono de carrito

```{python}
from scipy.stats import chi2_contingency



# Realizamos una funcion para realizar la pureba chi cuadrada de cada variable vs factores de abandono de carrito
def analyze_cart_abandonment(df, cart_abandonment_col, exclude_col=None):
 
    # Seleccionamos solo las variables categoricas (object, category, or bool types)
    categorical_columns = df.select_dtypes(include=['object', 'category', 'bool']).columns
    
    # Removemos la columna de abandono de carrito
    categorical_columns = [col for col in categorical_columns if col != cart_abandonment_col and col != exclude_col]
    
    if not categorical_columns:
        print("No categorical columns found in the DataFrame.")
        return
    
    rejected_columns = []

    for col in categorical_columns:
        print(f"\nAnalisis '{col}' vs '{cart_abandonment_col}':")
        
        # Creacion de tabla de contingenca
        cross_tab = pd.crosstab(df[col], df[cart_abandonment_col])
        print("Cross-Tabulation Table:")
        print(cross_tab)
        
        # Visualize de tabla de contingencia
        plt.figure(figsize=(10, 4))
        sns.heatmap(cross_tab, annot=True, fmt='d', cmap='coolwarm')
        plt.title(f'Cart Abandonment Factors por {col}')
        plt.show()
        
        #  Chi-Square test
        chi2, p, dof, expected = chi2_contingency(cross_tab)
        print(f"Chi-Square Statistic: {chi2}")
        print(f"p-value: {p}")
        print(f"Degrees of Freedom: {dof}")
        print("Expected Frequencies Table:")
        print(expected)
        print()

        alpha = .05
        if p < alpha:
            print(f'Conclusion: Como p_value ({p:.4f}) es menor a alpha de {alpha}, rechazamos la H0(hipotesis nula)')
            print()

            print(f'Por lo tanto hay diferencias significativas entre los grupos, es decir que hay evidencia estadistica para decir que existe una asociacion entre {col} y  Cart_Abandonment_Factors')
            rejected_columns.append(col)
        else:
            print(f'Conclusion: Como p_value  ({p:.4f}) es mayor a alpha de {alpha}, no hay suficiente evidencia para rechazar  H0(hipotesis nula)')
            print()

            print(f'Por lo tanto no hay diferencias significativas entre los grupos, es decir que NO hay evidencia estadistica para decir que existe una asociacion entre {col} y  Cart_Abandonment_Factors')


        print("-" * 50)
    
    return rejected_columns


analyze_cart_abandonment(df, 'Cart_Abandonment_Factors', exclude_col='Purchase_Categories') 
```

```{python}

        
        # Creacion de tabla de contingenca
        cross_tab = pd.crosstab(df_copy['Purchase_Categories'], df_copy['Cart_Abandonment_Factors'])
        print("Cross-Tabulation Table:")
        print(cross_tab)
        
        # Visualize de tabla de contingencia
        plt.figure(figsize=(10, 4))
        sns.heatmap(cross_tab, annot=True, fmt='d', cmap='coolwarm')
        plt.title(f'Cart Abandonment Factors por {col}')
        plt.show()
        
        #  Chi-Square test
        chi2, p, dof, expected = chi2_contingency(cross_tab)
        print(f"Chi-Square Statistic: {chi2}")
        print(f"p-value: {p}")
        print(f"Degrees of Freedom: {dof}")
        print("Expected Frequencies Table:")
        print(expected)
        print()

        alpha = .05
        if p < alpha:
            print(f'Conclusion: Como p_value ({p:.4f}) es menor a alpha de {alpha}, rechazamos la H0(hipotesis nula)')
            print()

            print(f'Por lo tanto hay diferencias significativas entre los grupos, es decir que hay evidencia estadistica para decir que existe una asociacion entre Purchase categories y  Cart_Abandonment_Factors')
            rejected_columns.append(col)
        else:
            print(f'Conclusion: Como p_value  ({p:.4f}) es mayor a alpha de {alpha}, no hay suficiente evidencia para rechazar  H0(hipotesis nula)')
            print()

            print(f'Por lo tanto no hay diferencias significativas entre los grupos, es decir que NO hay evidencia estadistica para decir que existe una asociacion entre Purchase categories y  Cart_Abandonment_Factors')


        print("-" * 50)
```

Conclusiones por categoria

Browsing_Frequency

- Se puede concluir que existe una relación entre la frecuencia de navegación y los factores de abandono de carrito, ya que los usuarios que se conectan algunas veces a la semana y encuentran mejores precios en otros sitios son quienes abandonan más el carrito.


Product_Search_Method
- Se puede concluir que existe una relación entre el método de búsqueda de producto y los factores de abandono de carrito, ya que los usuarios que buscan por categoría y cambian de opinión o ya no necesitan el artículo son quienes más abandonan el carrito.  Dime cuantas veces por se repite que la conclusion es una de estas cuatro , cambio de opinion y/o ya no necesia el articulo, encontrpo mejor precio en otro lugar, altos costos de envio, otros 


Search_Result_Exploration
Se puede concluir que existe una relación entre la exploración de resultados de búsqueda y los factores de abandono de carrito, ya que los usuarios que navegaron en múltiples páginas y encontraron un mejor precio en otro lugar son quienes más abandonan el carrito.

Cart_Completion_Frequency
- Se puede concluir que existe una relación entre la frecuencia con la que se completa el carrito y los factores de abandono de carrito, ya que los usuarios que seguido completan el carrito y que encuentran un precio en un mejor lugar son los que más abandonan.

Saveforlater_Frequency
- Se puede concluir que existe una relación entre el uso de la función "guardar para más tarde" y los factores de abandono de carrito, ya que los usuarios que a veces usan la función "guardar para más tarde" y que encuentran un precio en un mejor lugar son los que más abandonan.

Review_Reliability
- Se puede concluir que existe una relación entre la confianza en las reseñas de producto y los factores de abandono de carrito, ya que los usuarios que ocasionalmente confían en la reseña de producto y encuentran un precio en otro lugar son los que más abandonan.

Review_Helpfulness
- Se puede concluir que existe una relación entre la utilidad de la información de las reseñas de producto y los factores de abandono de carrito, ya que los usuarios que a veces encontraban utilidad en la información de las reseñas y cambiaban de opinión o ya no necesitaban el artículo son los que más abandonan.

Recommendation_Helpfulness
- Se puede concluir que existe una relación entre la utilidad de las recomendaciones y los factores de abandono de carrito, ya que los usuarios que hallaban las recomendaciones útiles y abandonaban por altos costos de envío son los que más abandonaban. Después de ahí, los que más abandonan son los que no habían encontrado las recomendaciones útiles y cambiaban de opinión o ya no necesitaban el artículo.

Service_Appreciation
- Se puede concluir que existe una relación entre el aspecto del servicio de Amazon que más apreciaban y los factores de abandono de carrito, ya que los usuarios que apreciaban el precio competitivo y encontraban un mejor precio en otro lugar son los que más abandonaban. Los segundos que más abandonan son los que apreciaban las recomendaciones de productos y abandonaban ya sea porque cambiaban de opinión y ya no necesitaban el artículo o porque encontraron un mejor precio en otro lugar.

Improvement_Areas
- Se puede concluir que existe una relación entre las áreas que se creen que deben mejorar y los factores de abandono de carrito, ya que los usuarios que creían que Amazon tenía que mejorar su servicio en respuesta de servicio al cliente abandonaban ya sea porque cambiaban de opinión y ya no necesitaban el artículo o porque encontraron un mejor precio en otro lugar.

### Conclusion general variables categoricas

Se puede observar en que pruebas se ve cual fue la categoria de abandono mas frecuente

Cambio de opinión y/o ya no necesitaba el artículo → 4 veces

- Product_Search_Method
- Review_Helpfulness
- Recommendation_Helpfulness
- Service_Appreciation

Encontró mejor precio en otro lugar → 6 veces

- Browsing_Frequency
- Search_Result_Exploration
- Cart_Completion_Frequency
- Saveforlater_Frequency
- Review_Reliability
- Service_Appreciation

Altos costos de envío → 1 vez

Recommendation_Helpfulness
Otros → 0 veces



En conclusion podemos decir que lo que mas impacta para el abandono del carrito es que los usarios encuentran mejor precio en otro lugar, seguido de que cambiaron de opinion o ya no necesitan el articulo

## Analisis variables numericas

En esta sección analizaremos las variables numericas que se tienen en el data set para tener una estadistica descriptiva de la recolección de datos

```{python}
# Obtenemos histogramas de las estadisticas numericas generales
coulumas_numericas =  df.columns.drop('id')

df[coulumas_numericas].hist(figsize=(15, 10))
```

```{python}
correlation = df_numerical_values.corr()
plt.figure(figsize=(10,10))
sns.heatmap(correlation,annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation matrix')
plt.show()
```

# Analisis objetivo: Factores abandono de carrito

```{python}
# Impreimimos los factores unicos de abandono 

print(df['Cart_Abandonment_Factors'].unique())
```

```{python}
factor_counts = df['Cart_Abandonment_Factors'].value_counts()

# Step 2: Sort the factors in descending order
factor_counts = factor_counts.sort_values(ascending=False)

percentage_per_value = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100

print(percentage_per_value)


value_counts = df['Cart_Abandonment_Factors'].value_counts(normalize=True) * 100
value_counts = value_counts.sort_values(ascending=True)  
        
        
plt.figure(figsize=(10, len(value_counts) / 2))
sns.barplot(x=value_counts.values, y=value_counts.index, orient='h')
plt.title(f'Cart_Abandonment_Factors')
plt.xlabel('Percentage (%)')
plt.ylabel(None)
      
        
for i, v in enumerate(value_counts.values):
    plt.text(v + 0.5, i, f"{v:.1f}%", color='black', va='center')
        

plt.show()

# Step 3: Calculate the cumulative percentage
cumulative_percentage = np.cumsum(factor_counts) / np.sum(factor_counts) * 100


# Step 4: Plot the Pareto chart
fig, ax1 = plt.subplots(figsize=(15,6))

# Bar plot for the frequencies
ax1.bar(factor_counts.index, factor_counts, color='b')
ax1.set_xlabel(None)
ax1.set_ylabel('Frequency', color='b')
ax1.tick_params(axis='y', labelcolor='b')

# Line plot for the cumulative percentage
ax2 = ax1.twinx()
ax2.plot(factor_counts.index, cumulative_percentage, color='r', marker='o')
ax2.set_ylabel('Cumulative Percentage', color='r')
ax2.tick_params(axis='y', labelcolor='r')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Display the chart
plt.title('Pareto Chart of Cart Abandonment Factors')
plt.show()
```

En el primer grafico de barras los factores de abandono de carrito podemos ver que los que mas sobresalen son que se encontro un mejor precio con un 42% y que mejor se cambia de opinion o ya no necesita mas el articulo con un 40% mientras que los otras dos categorias como la de alto costo de envio y otros representan el 11% y 5% respectivamente.

Despues de eso se hace un pareto para saber cules son los principales factores que se tendrian que analizar, que en este caso serian 'Se encontro un mejor precio en otro lugar y 'Se cambio de opinion o no necesita mas el articulo' pues son las que mas efectos tienen al abandono

```{python}
# Hacemo un box plot de los factores de abandono vs edad

categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['age'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'age', data=filtered_df)
```

Eliminar valores atipicos(gente menor de edad)

-Su hijo le comopro
-Posible typo

```{python}
#Factores de abandono vs importancia de resenas de cliente


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['Customer_Reviews_Importance'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Customer_Reviews_Importance', data=filtered_df)


# algo 
```

```{python}
#Factores de abandono vs Que tan seguido se recibe recomendaciones personalizadas


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  # Filter DataFrame for the current console
    descripcion = filtered_df['Personalized_Recommendation_Frequency_2'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Personalized_Recommendation_Frequency_2', data=filtered_df)
```

```{python}
#Factores de abandono vs Que tan seguido se recibe recomendaciones personalizadas


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  
    descripcion = filtered_df['Rating_Accuracy'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Rating_Accuracy', data=filtered_df)
```

```{python}
#Factores de abandono vs Satisfaction de la compra


categoria_abandono = ['Found a better price elsewhere','Changed my mind or no longer need the item']





for categoria in categoria_abandono:
    filtered_df = df[df['Cart_Abandonment_Factors'] == categoria]  
    descripcion = filtered_df['Shopping_Satisfaction'].describe() 
    print(f"Cart_Abandonment_Factors: {categoria}")
    print(descripcion)




filtered_df = df[df['Cart_Abandonment_Factors'].isin(categoria_abandono)]


plt.figure(figsize=(10,8))
sns.boxplot(x = 'Cart_Abandonment_Factors', y = 'Shopping_Satisfaction', data=filtered_df)
```

